---
title: HuggingFace
pcx_content_type: get-started

---

[HuggingFace](https://huggingface.co/) helps users build, deploy and train machine learning models.

## Endpoint

`https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface`

## URL structure

When making requests to HuggingFace Inference API, replace `https://api-inference.huggingface.co/models/` in the URL you’re currently using with `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface`. Note that the model you’re trying to access should come right after, for example `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface/bigcode/starcoder`.

## Examples

```bash title="Request"
curl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface/bigcode/starcoder \
  --header 'Authorization: Bearer {hf_api_token}' \
  --header 'Content-Type: application/json' \
  --data '{
    "inputs": "console.log"
}'
```

If you are using the HuggingFace.js library, you can set your inference endpoint like this:

```js title="JavaScript"
import { HfInferenceEndpoint } from '@huggingface/inference';

const accountId = '{account_id}';
const gatewayId = '{gateway_id}';
const model = 'gpt2';
const baseURL = `https://gateway.ai.cloudflare.com/v1/${accountId}/${gatewayId}/huggingface/${model}`;
const apiToken = env.HF_API_TOKEN;

const hf = new HfInferenceEndpoint(
  baseURL,
  apiToken
);
```
