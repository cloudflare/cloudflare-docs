---
pcx_content_type: how-to
title: Logpush integration
sidebar:
  order: 8
---

:::note
Only available on Enterprise plans.
:::

With Cloudflare's [Logpush](/logs/about/) service, you can configure the automatic export of Zero Trust logs to third-party storage destinations or to security information and event management (SIEM) tools. Once exported, your team can analyze and audit the data as needed.

## Export Zero Trust logs with Logpush

:::caution[Dashboard limitation]
Zero Trust does not support configuring [Cloudflare R2](/logs/get-started/enable-destinations/r2/) as a Logpush destination in the dashboard. To use R2 as a destination for Zero Trust logs, configure your Logpush jobs [with the API](/logs/get-started/enable-destinations/r2/#manage-via-api).
:::

To enable Logpush for Zero Trust logs:

1. In [Zero Trust](https://one.dash.cloudflare.com/), go to **Logs** > **Logpush**.
2. Select **Add Logpush job**.
3. Enter a **Job name**.
4. From the drop-down menu, choose the [dataset](#zero-trust-datasets) to export.
5. Next, select the data fields you want to include in the log.
6. In **Advanced settings**, choose the timestamp format you prefer, and whether you want to enable logs sampling.
7. Select **Next**.
8. Select the service you want to export your logs to.
9. Follow the service-specific instructions in Zero Trust to validate your destination.

The setup of your Logpush integration is now complete. Logpush will send updated logs every five minutes to your selected destination.

You can configure multiple destinations and add additional fields to your logs by returning to the **Logpush** page.

## Zero Trust datasets

Refer to the Logpush documentation for a list of available fields.

| Dataset                                                                         | Description                                                    |
| ------------------------------------------------------------------------------- | -------------------------------------------------------------- |
| [Gateway DNS](/logs/reference/log-fields/account/gateway_dns/)                  | DNS queries inspected by Cloudflare Gateway                    |
| [Gateway HTTP](/logs/reference/log-fields/account/gateway_http/)                | HTTP requests inspected by Cloudflare Gateway                  |
| [Gateway Network](/logs/reference/log-fields/account/gateway_network/)          | Network packets inspected by Cloudflare Gateway                |
| [Audit Logs](/logs/reference/log-fields/account/audit_logs/)                    | Authentication events through Cloudflare Access                |
| [Access Requests](/logs/reference/log-fields/account/access_requests/)          | HTTP requests to sites protected by Cloudflare Access          |
| [CASB Findings](/logs/reference/log-fields/account/casb_findings/)              | Security issues detected by Cloudflare CASB                    |
| [Device Posture](/logs/reference/log-fields/account/device_posture_results/)    | Device posture status from the WARP client                     |
| [Session Logs](/logs/reference/log-fields/account/zero_trust_network_sessions/) | Network session logs for traffic proxied by Cloudflare Gateway |

## Parse Logpush logs

Cloudflare Gateway logs DNS query information in [resource record format](https://datatracker.ietf.org/doc/html/rfc1035#section-4.1.3), a Base64-encoded binary format. The following resource record fields are available for each query:

- Query name
- Query type
- Query class
- Response TTL
- Response data

To parse resource record logs from Logpush, run the following Python script with your desired samples:

```python
import dnslib
import base64


# The samples from your Logpush output
samples = [
   {"type":"1","data":"BnJlZGRpdANjb20AAAEAAQAAALwABJdlwYw="},
   {"type":"5","data":"BnNlY3VyZQV3bHhycwNjb20AAAUAAQAADggAIgZzZWN1cmUEYmFzZQV3bHhycwNjb20GYWthZG5zA25ldAA="},
   {"type":"28","data":"Bmdvb2dsZQNjb20AABwAAQAAAGkAECYH+LBAIxAJAAAAAAAAAGU="}]


# Parse the Logpush RData.data field into Resource Records
# See section "4.1.3. Resource record format" of https://www.ietf.org/rfc/rfc1035.txt
# Includes Query Name, Query Type, Query Class, Response TTL, Response Data
for sample in samples:
   decoded = base64.b64decode(sample["data"])
   buffer = dnslib.DNSBuffer(decoded)
   r = dnslib.RR.parse(buffer)
   print("== Print the full Resource Record ==")
   print(r)
   print("== Print individual components of the Resource Record ==")
   query_name = r.rname
   query_type = r.rtype
   query_class = r.rclass
   response_ttl = r.ttl
   response_data = r.rdata
   print(f"query name: {query_name} | query type: {query_type} | query class: {query_class} | ttl: {response_ttl} | rdata: {response_data}\n")
```

The script will print a list of your samples. For example:

```txt
== Print the full Resource Record ==
reddit.com.             188     IN      A       151.101.193.140
== Print individual components of the Resource Record ==
query name: reddit.com. | query type: 1 | query class: 1 | ttl: 188 | rdata: 151.101.193.140

== Print the full Resource Record ==
secure.wlxrs.com.       3592    IN      CNAME   secure.base.wlxrs.com.akadns.net.
== Print individual components of the Resource Record ==
query name: secure.wlxrs.com. | query type: 5 | query class: 1 | ttl: 3592 | rdata: secure.base.wlxrs.com.akadns.net.

== Print the full Resource Record ==
google.com.             105     IN      AAAA    2607:f8b0:4023:1009::65
== Print individual components of the Resource Record ==
query name: google.com. | query type: 28 | query class: 1 | ttl: 105 | rdata: 2607:f8b0:4023:1009::65
```
