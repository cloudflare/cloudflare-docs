---
link: "/workers-ai/changelog/"
productName: Workers AI
productLink: "/workers-ai/"
productArea: Developer platform
productAreaLink: /workers/platform/changelog/platform/
entries:

- publish_date: '2024-06-27'
  title: Introducing embedded function calling
  description: |-
    - A new way to do function calling with [Embedded function calling](/workers-ai/function-calling/embedded)
    - Published new [`@cloudflare/ai-utils`](https://www.npmjs.com/package/@cloudflare/ai-utils) npm package
    - Open-sourced [`ai-utils on Github`](https://github.com/cloudflare/ai-utils)

- publish_date: '2024-06-19'
  title: Added support for traditional function calling
  description: |-
    - [Function calling](/workers-ai/function-calling/) is now supported on enabled models
    - Properties added on [models](/workers-ai/models/) page to show which models support function calling

- publish_date: '2024-06-18'
  title: Native support for AI Gateways
  description: |-
    Workers AI now natively supports [AI Gateway](/ai-gateway/providers/workersai/#worker).

- publish_date: '2024-06-11'
  title: Deprecation announcement for `@cf/meta/llama-2-7b-chat-int8`
  description: |-
    We will be deprecating `@cf/meta/llama-2-7b-chat-int8` on 2024-06-30.

    Replace the model ID in your code with a new model of your choice:
    - [`@cf/meta/llama-3-8b-instruct`](/workers-ai/models/llama-3-8b-instruct/) is the newest model in the Llama family (and is currently free for a limited time on Workers AI).
    - [`@cf/meta/llama-3-8b-instruct-awq`](/workers-ai/models/llama-3-8b-instruct-awq/) is the new Llama 3 in a similar precision to your currently selected model. This model is also currently free for a limited time.

    If you do not switch to a different model by June 30th, we will automatically start returning inference from `@cf/meta/llama-3-8b-instruct-awq`.

- publish_date: '2024-05-29'
  title: Add new public LoRAs and note on LoRA routing
  description: |-
    * Added documentation on [new public LoRAs](/workers-ai/fine-tunes/public-loras/).
    * Noted that you can now run LoRA inference with the base model rather than explicitly calling the `-lora` version


- publish_date: '2024-05-17'
  title: Add OpenAI compatible API endpoints
  description: |-
    Added OpenAI compatible API endpoints for `/v1/chat/completions` and `/v1/embeddings`. For more details, refer to [Configurations](/workers-ai/configuration/open-ai-compatibility/).

- publish_date: '2024-04-11'
  title: Add AI native binding
  description: |-
    * Added new AI native binding, you can now run models with `const resp = await env.AI.run(modelName, inputs)`
    * Deprecated `@cloudflare/ai` npm package. While existing solutions using the @cloudflare/ai package will continue to work, no new Workers AI features will be supported.
      Moving to native AI bindings is highly recommended
